<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DISCO">
  <meta property="og:title" content="DISCO"/>
  <meta property="og:description" content="DISCO"/>
  <meta property="og:url" content="https://arubique.github.io/disco-site/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="DISCO: Diversified Sample Condensation for Accelerating Model Evaluation">
  <meta name="twitter:description" content="DISCO: Diversified Sample Condensation for Accelerating Model Evaluation">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/disco2.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="diversified sample condensation; model evaluation; efficient evaluation; anchor points">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>DISCO: Diversified Sample Condensation for Accelerating Model Evaluation</title>
  <link rel="icon" type="image/x-icon" href="static/images/disco2.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">DISCO: Diversified Sample Condensation for Accelerating Model Evaluation</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=upi0cDcAAAAJ&hl=en" target="_blank">Alexander Rubinstein</a>,</span>
                <span class="author-block">
                    <a>Benjamin Raible</a>,</span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=Jt4OYwMAAAAJ&hl=fr" target="_blank">Martin Gubri</a>,</span>

                  <span class="author-block">
                    <a href="https://scholar.google.com/citations?hl=en&user=kmXOOdsAAAAJ" target="_blank">Seong Joon Oh</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Tübingen AI Center, University of Tübingen
                        <!-- <br>Conferance name and year -->
                    </span>
                    <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <!-- <span class="link-block">
                        <a href="https://arxiv.org/pdf/2504.07092.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span> -->

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <!-- <a href="https://github.com/AlexanderRubinstein/OCCAM" target="_blank" -->
                    <a href="https://github.com/arubique/disco-public" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <!-- <a href="https://arxiv.org/abs/2504.07092" target="_blank" -->
                  <a href="https://arxiv.org/abs/XXX" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%"> -->
        <!-- Your video here -->
        <!-- <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus.
      </h2>
    </div>
  </div>
</section> -->
<!-- End teaser video -->

<!-- Teaser figure-->
<section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <img src="static/images/teaser-v2-400.png" alt="Banner image" width="100%">
        <h2 class="subtitle has-text-centered" style="margin-top: 2em;">
            <b>Imbalance:</b> More evaluation budget is spent
            on less informative samples in test sets.
        </h2>
      </div>
    </div>
  </section>
  <!-- End teaser figure -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            <!-- Evaluating modern machine learning models has become prohibitively expensive.
            Benchmarks such as LMMs-Eval and HELM demand thousands of GPU hours per model,
            limiting thorough evaluation to resource-rich labs and discouraging experimentation.
            Prior approaches reduce cost by selecting fixed subsets of data, yet often rely on brittle heuristics
            or task-specific signals. We introduce <b>Diversified Sample Condensation (DISCO)</b>, a general framework for cost-efficient evaluation.
            DISCO selects samples with high inter-model predictive disagreement,
            capturing the most informative evaluation points. A model is then represented by the model signature,
            the concatenation of its predictions on this reduced set. Its full performance is estimated via regression.
            DISCO reduces evaluation cost by up to 99.3% on MMLU and 99.8% ImageNet with only 1%p error in accuracy estimation,
            demonstrating a superior efficiency-precision trade-off to existing efficient evaluation methods.
             -->
             Evaluating modern machine learning models has become prohibitively expensive. Benchmarks such as LMMs-Eval and HELM demand thousands of GPU hours per model. Costly evaluation reduces inclusivity, slows the cycle of innovation, and worsens environmental impact.
             The typical approach follows two steps. First, select an anchor subset of data. Second, train a mapping from the accuracy on this subset to the final test result. The drawback is that anchor selection depends on clustering, which can be complex and sensitive to design choices. We argue that promoting diversity among samples is not essential; what matters is to select samples that <i>maximise diversity in model responses</i>.
             Our method, <b>Diversifying Sample Condensation (DISCO)</b>, selects the top-k samples with the greatest model disagreements. This uses greedy, sample-wise statistics rather than global clustering. The approach is conceptually simpler. From a theoretical view, inter-model disagreement provides an information-theoretically optimal rule for such greedy selection. <b>DISCO</b> shows empirical gains over prior methods, achieving state-of-the-art results in performance prediction across MMLU, Hellaswag, Winogrande, and ARC.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <!-- <div id="results-carousel" class="carousel results-carousel" data-pause-on-hover="true" data-autoplay="false"> -->
        <div id="results-carousel" class="carousel results-carousel" data-pause-on-hover="true">
        <div class="item">
        <!-- Your image here -->
        <img src="static/images/problem-400.png" alt="problem statement: efficient evaluation"/>
        <h2 class="subtitle has-text-centered">
            <b>Problem overview.</b> We aim at selecting a much smaller evaluation dataset
            than the original evaluation dataset, while keeping the estimated performances
            as close as possible.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/method_details-400.png" alt="method details"/>
        <h2 class="subtitle has-text-centered">
            <b>DISCO overview.</b> First, we select a subset of an evaluation dataset with the most
            informative samples. Second, we predict the performance of unseen models from their outputs on the
            selected samples.
        </h2>
      </div>
     <div class="item">
      <!-- Your image here -->
      <img src="static/images/results.png" width="85%" alt="results" style="display: block; margin-left: auto; margin-right: auto;"/>
      <h2 class="subtitle has-text-centered">
        <b>DISCO compression of MMLU, HellaSwag, Winogrande and Arc datasets.</b> We compare our DISCO against baselines.
        For each dataset, we reduce the test set to 100 data points, achieving inference cost reduction of up to 99.3%
        and 99.0% on MMLU and HellaSwag, respectively. Main metrics are mean absolute error (MAE),
        measured in %p difference in accuracy, and the Spearman rank correlation (Rank) between the true model
        ranking and the estimated model ranking. Main observations: (1) Model signature is an effective strategy for
        performance estimation. (2) Condensing dataset into the top-k diversifying samples (e.g. according to Predictive Diversity Score (PDS)) allows DISCO to achieve the state of the art in test-set compression.
      </h2>
    </div>
    <div class="item">
        <!-- Your image here -->
        <img src="static/images/vision-results.png" alt="results" width="40%" style="display: block; margin-left: auto; margin-right: auto;"/>
        <h2 class="subtitle has-text-centered">
          <b>DISCO compression of ImageNet validation dataset.</b> We evaluate the generalisation of our DISCO to the computer vision domain. The main metrics are mean absolute error (MAE), measured in %p difference in accuracy, and the Spearman rank correlation (Rank) between the true model ranking and the estimated model ranking. Main observations: (1) Same as for language experiments, model signature is an effective strategy for performance estimation. (2) Using PDS on top improves performance even more.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/num-anchors.png" alt="results" style="display: block; margin-left: auto; margin-right: auto;"/>
        <h2 class="subtitle has-text-centered">
          <b>MMLU performance estimation vs. compression rates.</b> Mean absolute error (MAE), measured in %p difference in accuracy, and the Spearman rank correlation between the true model ranking and the estimated model ranking are shown. At 100 samples, the results are identical to Table \ref{tab:language-main}. Main observations: DISCO hits a better efficiency-precision trade-off across all range of compression rates. For extreme compression rate, kNN is a better choice than random forest (RF).
        </h2>
      </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->


<!-- \textbf{MMLU performance estimation vs. compression rates}. Mean absolute error (MAE), measured in \%p difference in accuracy, and the Spearman rank correlation between the true model ranking and the estimated model ranking are shown. At 100 samples, the results are identical to Table \ref{tab:language-main}. \textbf{Main observations}: \method hits a better efficiency-precision trade-off across all range of compression rates. For extreme compression rate, kNN is a better choice than random forest (RF). -->


<!-- \textbf{\methodbf compression of ImageNet validation dataset.} We evaluate the generalisation of our \method to the computer vision domain. The main metrics are mean absolute error (MAE), measured in \%p difference in accuracy, and the Spearman rank correlation (Rank) between the true model ranking and the estimated model ranking. \textbf{Main observations}: (1) Same as for language experiments, model signature is an effective strategy for performance estimation. (2) Using PDS on top improves performance even more. -->


<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container"> -->
      <!-- Paper video. -->
      <!-- <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">

          <div class="publication-video"> -->
            <!-- Youtube embed code here -->
            <!-- <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%"> -->
            <!-- Your video file here -->
            <!-- <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%"> -->
            <!-- Your video file here -->
            <!-- <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\ -->
            <!-- Your video file here -->
            <!-- <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>  -->
<!-- End video carousel -->






<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>

      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <!-- <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section> -->
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template.</a>
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->

<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
